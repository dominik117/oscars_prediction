{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis 2: NLP Critic's Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(680,) (171,) (680,) (171,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 680/680 [00:02<00:00, 254.22it/s]\n",
      "100%|██████████| 171/171 [00:00<00:00, 281.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.22 s, sys: 45.3 ms, total: 3.27 s\n",
      "Wall time: 3.34 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_nlp2 = df[[\"Critic_Review\", \"Won_Oscars\"]]\n",
    "# Assuming you have your features and target variables\n",
    "X = df_nlp2['Critic_Review']  # Features\n",
    "y = df_nlp2['Won_Oscars']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "def remove_accented_chars(text):\n",
    "  text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "  return text\n",
    "\n",
    "def pre_process_corpus(docs):\n",
    "  norm_docs = []\n",
    "  for doc in tqdm.tqdm(docs):\n",
    "    # remove extra newlines and tabs \\ spaces\n",
    "    doc = doc.translate(doc.maketrans(\"\\n\\t\\r\", \"   \"))\n",
    "    # lowercase the text\n",
    "    doc = doc.lower()\n",
    "    # remove accented characters from text => convert to plain english\n",
    "    doc = remove_accented_chars(doc)\n",
    "    # expand contractions i.e. won't => would not\n",
    "    doc = contractions.fix(doc)\n",
    "\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, flags=re.I|re.A)\n",
    "    doc = re.sub(' +', ' ', doc) # remove extra spaces between words\n",
    "    doc = doc.strip()\n",
    "\n",
    "    norm_docs.append(doc)\n",
    "\n",
    "  return norm_docs\n",
    "\n",
    "norm_train_reviews = pre_process_corpus(X_train)\n",
    "norm_test_reviews = pre_process_corpus(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW model:> Train features shape: (680, 91251)  Test features shape: (171, 91251)\n",
      "TFIDF model:> Train features shape: (680, 91251)  Test features shape: (171, 91251)\n",
      "CPU times: user 8.76 s, sys: 199 ms, total: 8.96 s\n",
      "Wall time: 9.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# build BOW features on train reviews\n",
    "cv = CountVectorizer(binary=False, min_df=5, max_df=1.0, ngram_range=(1,2))\n",
    "# min_df=5, max_df=1.0 -> remove words occuring in < 5 documents (very rare words), keep words even if occuring in 100% (all) of docs\n",
    "# ngram_range=(1,2) -> words and bigrams as features\n",
    "cv_train_features = cv.fit_transform(norm_train_reviews)\n",
    "\n",
    "# build TFIDF features on train reviews\n",
    "tv = TfidfVectorizer(use_idf=True, min_df=5, max_df=1.0, ngram_range=(1,2),\n",
    "                     sublinear_tf=True)\n",
    "tv_train_features = tv.fit_transform(norm_train_reviews)\n",
    "\n",
    "# transform test reviews into features\n",
    "# we use .transform(..) and NOT .fit_transform(..)\n",
    "# to use vocabulary learnt during training data as our features\n",
    "cv_test_features = cv.transform(norm_test_reviews)\n",
    "\n",
    "tv_test_features = tv.transform(norm_test_reviews)\n",
    "\n",
    "print('BOW model:> Train features shape:', cv_train_features.shape, ' Test features shape:', cv_test_features.shape)\n",
    "print('TFIDF model:> Train features shape:', tv_train_features.shape, ' Test features shape:', tv_test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.78      0.95      0.86       127\n",
      "        True       0.62      0.23      0.33        44\n",
      "\n",
      "    accuracy                           0.77       171\n",
      "   macro avg       0.70      0.59      0.60       171\n",
      "weighted avg       0.74      0.77      0.72       171\n",
      "\n",
      "CPU times: user 936 ms, sys: 18.6 ms, total: 955 ms\n",
      "Wall time: 985 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>121</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          negative  positive\n",
       "negative       121         6\n",
       "positive        34        10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Random Forest model on BOW features\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# instantiate model\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=140,\n",
    "    max_depth=20,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    class_weight='balanced',\n",
    "    random_state=15)\n",
    "\n",
    "# train model\n",
    "rf.fit(cv_train_features, y_train)\n",
    "\n",
    "# predict on test data\n",
    "rf_bow_predictions = rf.predict(cv_test_features)\n",
    "\n",
    "labels = ['negative', 'positive']\n",
    "print(classification_report(y_test, rf_bow_predictions))\n",
    "pd.DataFrame(confusion_matrix(y_test, rf_bow_predictions), index=labels, columns=labels)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
